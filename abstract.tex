\begin{abstract}

Big data processing and storage has grown into on of the most important aspects
  of distributed computing in the last years. Much of the effort in this area
  goes into sophisticated algorithm and architectures which provides a small
  leap to a more efficient big data system. This works explores a novel idea in
  which by modifying  a simple component found in most of the distributed
  systems it leads to an significant improvement the overall performance of the
  underline system which is often blind to this modification. This small
  component is file partition which split the workload of a distributed job
  into small working units. \\ \\

This work proposes a different view of file partitioning which separates
  conventional simple partition of a file into multiple blocks to a more
  sophisticated system in which those blocks can change its size at running
  time and therefore, adjusting the amount of input of each of the working
  units of the distributed job. The power that this technique unleashes and
  enormous power since it can be virtually plugged to any Distributed system
  and improve its system utilization and performance. In this research we plug
  in our proposed file partitioning system at on the the key system of data
  processing of our time, Apache Hadoop.\\ \\

Coincidentally, this thesis also presents a novel distributed file system named
  VeloxDFS which implements elastic blocks and can be used as a substitute of
  Hadoop Distributed File System among other remarkable features. 


\vfill
\clearpage
\end{abstract}
